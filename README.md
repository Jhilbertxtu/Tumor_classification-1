# Tumor_classification

Data Mining Project

Abstract:  The main purpose of this project is to classify tumors based on features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass as either benign or malignant. The motivation behind this project is to be able to find a model that will be able to analyze new tumors and predict whether the observed tumor is malignant or not.  This can be used to better assess patients who might have breast cancer.  To solve this problem, I decided to employ two machine learning algorithms to build my classifiers, classification trees and logistic regression.  To compare the performance of my classifiers I plotted the ROC curve and computed the AUC (Area under the curve) of all my models.  The AUC of my base tree was 0.935 and after pruning increased to 0.945.  My base logistic regression resulted in an AUC of 0.90795 and after using the step function to find the model with lowest AIC, my final model had an AUC of 0.98606.  Therefore, it appears that logistic regression appears to be the better method of classifying this data.
Introduction:  This classification problem was brought to my attention from the professor but I believe it is a very interesting problem because of how useful a successful model can be.  The purpose of this project is to classify tumors as benign or malignant using decision trees from the tree package and logistic regression from the caret package and the stats package.  These classifiers can then be used in real life to diagnose individuals with tumors.  Per the description of the data set found on the UCI ML website the data contains:
Ten real-valued features are computed for each cell nucleus: a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension ("coastline approximation" - 1). The mean, standard error and ‘worst’ or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.  Class distribution: 357 benign, 212 malignant.
My results came out better than I expected since all my models had an AIC over 0.9, which is suspicious.  The model validation and analysis of my results will be described in detail further in my report and will explain the high accuracy.  I received this data Kaggle.com but the original source comes from the UCI Machine learning directory.  To accomplish this project, I relied on the R programming language for the main analysis and Tableau for data visualizations.  Cross validation was employed in both methods to avoid over-fitting our model to our training data.  To validate our models, we tracked misclassification error rates for the decision trees and Accuracy from a confusion matrix for the logistic regression model.

Main Body:  All the attributes, except for Diagnosis, id and X, are numeric.  I summed all null values in the dataset and found that there were no nulls except for the entire X column being null.  I then created a numeric label for the diagnosis making malignant stand as 1 and benign as 0.  I then removed the columns Diagnosis, id and X since they would not be useful in the rest of the analysis. I then created a pairwise matrix between the ten real valued features accounting for the three different measures to identify any relationship between the attributes.  Most of the positive relationships can be explained because some attributes are computed from others, such as the radius and area.  My first step was to create a base decision tree including all the covariates.   This tree had concave point worst as its root node and was five levels deep.  The tree had a misclassification error rate of 0.01754, which is quite high considering we have not optimized it.  The ROC curve was plotted and an AUC value of 0.935 was returned for this model, which again is quite high.  One reason why the tree might be performing so well might be that it is over fitting to the training set.  To correct this I performed the cross-validation function on my tree to prune it.  Looking at the plot outputted from the cross-validation object we see that deviance is at a minimum when the number of terminal nodes is 5.  We then apply the prune.misclass function to our base tree to create a new decision tree with only five terminal nodes.   The new pruned tree has a higher error rate of 0.02256 which might imply that our original tree was over fitting.  To determine which of these trees is better we compare both tree’s AUC values.  The basic model had an AUC of 0.935, while the pruned tree had an AUC of 0.945.  Therefore, we conclude that the pruned model performs better than the basic model even though it had a higher misclassification error.  The higher value of AUC for our pruned tree also supports our previous assumption that the base model was over fitting to our training set.  My next step was to create a logistic regression model that included all the covariates to act as my base model for my second method.  I also applied a repeated ten-fold cross validation to the model and used the train function from the caret package to implement the cross validation.  From the cross validated model, I created the confusion matrix and received an Accuracy of 91.76%.  The accuracy is defined as the number of true positives plus the number of true negatives divided by total number of observations.  The ROC curve for the base glm model returned an AUC of 0.90795, which is lower than both of our tree models.  To find the best model, I employed the forward step function with AIC as my information criteria.  This function essentially starts with no covariates and will introduce covariates until the AIC criterion is no longer improved.  The model returned by the step function has an AIC of 56.79 and includes eight attributes.  My next step is to apply the same tenfold cross validation as done previously.  I compute the confusion matrix for this new model and receive a much-improved accuracy score of 97.06%.  My final step is to plot the ROC curve and compute the AUC of my final model, which is AUC of 0.98606.  Comparing classification rates and AUC across all my models I reach the conclusion that my second logistic regression model with ten-fold cross validation is my best model since it has a similar misclassification error rate as my best tree model but much higher AUC.  One final consideration is that R suggested that there is complete or quasi complete separation in my linear regression model.  Per the IDRE at UCLA: 
“If it is quasi-complete separation, the easiest strategy is the "Do nothing" strategy. This is because that the maximum likelihood for other predictor variables are still valid. The drawback is that we don't get any reasonable estimate for the variable X that actually predicts the outcome variable effectively.  This strategy does not work well for the situation of complete separation.”
To determine the extent of the separation I decided to plot the covariates in my final model and their diagnosis to identify which covariate was the problem.  I was unable to find a case of complete separation and concluded I must be dealing with quasi complete separation.  Quasi complete separation is defined as an, “outcome variable that separates a predictor variable or a combination of predictor variables to certain degree.”  Following the suggestion provided by the quote above I decided to not interfere with my model.
Conclusion:  At the beginning of this project my goal was to have the best predictive model for this data.  I think it is safe to say that my model with 97.06% accuracy is successful enough to classify new data and diagnose tumors.  I would like to thank Professor Oh for the guidance on the project and the various articles I relied on for additional information.
References:
http://www.edureka.co/blog/implementation-of-decision-tree/
http://ecology.msu.montana.edu/labdsv/R/labs/lab6/lab6.html#deviance
https://www.r-bloggers.com/evaluating-logistic-regression-models/
http://www.ats.ucla.edu/stat/mult_pkg/faq/general/complete_separation_logit_models.htm

  
                     


